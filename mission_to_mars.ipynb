{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import shutil\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate browser helper function\n",
    "def init_browser():\n",
    "    exec_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    return Browser('chrome', **exec_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of URLs to explore and scrape\n",
    "url1 = 'https://mars.nasa.gov/news/'\n",
    "url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "url3 = 'https://twitter.com/marswxreport?lang=en'\n",
    "url4 = 'http://space-facts.com/mars/'\n",
    "url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars News URL (url1)\n",
    "browser = init_browser()\n",
    "browser.visit(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "html = requests.get(url1)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "# Get title & paragraph text\n",
    "news_title_1 = soup.find('div', 'content_title', 'a').text\n",
    "news_p_1 = soup.find('div', 'rollover_description_inner').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title = news_title_1.strip()\n",
    "news_p = news_p_1.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opportunity Hunkers Down During Dust Storm\n",
      "It's the beginning of the end for the planet-encircling dust storm on Mars. But it could still be weeks, or even months, before skies are clear enough for NASA's Opportunity rover to recharge its batteries and phone home.\n"
     ]
    }
   ],
   "source": [
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars Featured Image (url2)\n",
    "browser = init_browser()\n",
    "browser.visit(url2)\n",
    "time.sleep(1)\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "time.sleep(1)\n",
    "expand = browser.find_by_css('a.fancybox-expand')\n",
    "expand.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "jpl_html = browser.html\n",
    "jpl_soup = BeautifulSoup(jpl_html, 'html.parser')\n",
    "\n",
    "# Get the featured image url\n",
    "img_relative = jpl_soup.find('img', class_='fancybox-image')['src']\n",
    "featured_image_url = f'https://www.jpl.nasa.gov{img_relative}'\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and save the image from 'feautured_image'url\n",
    "response = requests.get(featured_image_url,stream=True)\n",
    "with open('img.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image \n",
    "from IPython.display import Image\n",
    "Image(url='img.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars Weather URL (url3)\n",
    "browser = init_browser()\n",
    "browser.visit(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather using BeautifulSoup\n",
    "html_weather = browser.html\n",
    "soup = BeautifulSoup(html_weather, \"html.parser\")\n",
    "for text in browser.find_by_css('.tweet-text'):\n",
    "    if text.text.partition(' ')[0] == 'Sol':\n",
    "        mars_weather = text.text\n",
    "        break\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars Facts URL (url4)\n",
    "browser = init_browser()\n",
    "browser.visit(url4)\n",
    "time.sleep(1)\n",
    "\n",
    "# Get mars facts using BeautifulSoup\n",
    "mars_facts_html = browser.html\n",
    "mars_facts_soup = BeautifulSoup(mars_facts_html, 'html.parser')\n",
    "\n",
    "fact_table = mars_facts_soup.find('table', class_='tablepress tablepress-id-mars')\n",
    "column1 = fact_table.find_all('td', class_='column-1')\n",
    "column2 = fact_table.find_all('td', class_='column-2')\n",
    "\n",
    "facets = []\n",
    "values = []\n",
    "\n",
    "for row in column1:\n",
    "    facet = row.text.strip()\n",
    "    facets.append(facet)\n",
    "    \n",
    "for row in column2:\n",
    "    value = row.text.strip()\n",
    "    values.append(value)\n",
    "    \n",
    "mars_facts = pd.DataFrame({\n",
    "    \"Facet\":facets,\n",
    "    \"Value\":values\n",
    "    })\n",
    "\n",
    "mars_facts_html = mars_facts.to_html(header=False, index=False)\n",
    "mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars Hemispheres URL (url5) & Loop through the four tags\n",
    "\n",
    "mars_hemisphere_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "hemi_dicts = []\n",
    "\n",
    "for i in range(1,9,2):\n",
    "    hemi_dict = {}\n",
    "    \n",
    "    browser.visit(mars_hemisphere_url)\n",
    "    time.sleep(1)\n",
    "    hemispheres_html = browser.html\n",
    "    hemispheres_soup = BeautifulSoup(hemispheres_html, 'html.parser')\n",
    "    hemi_name_links = hemispheres_soup.find_all('a', class_='product-item')\n",
    "    hemi_name = hemi_name_links[i].text.strip('Enhanced')\n",
    "    \n",
    "    detail_links = browser.find_by_css('a.product-item')\n",
    "    detail_links[i].click()\n",
    "    time.sleep(1)\n",
    "    browser.find_link_by_text('Sample').first.click()\n",
    "    time.sleep(1)\n",
    "    browser.windows.current = browser.windows[-1]\n",
    "    hemi_img_html = browser.html\n",
    "    browser.windows.current = browser.windows[0]\n",
    "    browser.windows[-1].close()\n",
    "    \n",
    "    hemi_img_soup = BeautifulSoup(hemi_img_html, 'html.parser')\n",
    "    hemi_img_path = hemi_img_soup.find('img')['src']\n",
    "\n",
    "    print(hemi_name)\n",
    "    hemi_dict['title'] = hemi_name.strip()\n",
    "    \n",
    "    print(hemi_img_path)\n",
    "    hemi_dict['img_url'] = hemi_img_path\n",
    "\n",
    "    hemi_dicts.append(hemi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - MongoDB and Flask Application\n",
    "\n",
    "Convert Jupyter notebook into a Python script called scrape_mars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
